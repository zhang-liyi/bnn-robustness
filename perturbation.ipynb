{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Data Perturbation & Bayesian Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUkBNeEeNxcZ"
   },
   "source": [
    "## Deep Learning Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi-P-cgcPdr_"
   },
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdXIzBqcEnGQ",
    "outputId": "05f4c82c-de74-4d94-d048-10d5bd481fa5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.nn import softmax\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "x_train, x_val = tf.split(x_train, [50000, 10000], axis=0)\n",
    "y_train, y_val = tf.split(y_train, [50000, 10000], axis=0)\n",
    "\n",
    "batch_size = 10000\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "val_size = x_val.shape[0]\n",
    "img_length = x_train.shape[1] * x_train.shape[2]\n",
    "img_shape1 = x_train.shape[1]\n",
    "img_shape2 = x_train.shape[2]\n",
    "num_classes = 10\n",
    "\n",
    "x_train = x_train/126\n",
    "x_val = x_val/126\n",
    "x_test = x_test/126\n",
    "y_train = tf.one_hot(y_train, num_classes)/1\n",
    "y_val = tf.one_hot(y_val, num_classes)/1\n",
    "y_test = tf.one_hot(y_test, num_classes)/1\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size)\n",
    "#val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "path = 'results/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e59qJjNAPgE3"
   },
   "source": [
    "Define, train, and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FcT15jGEnJl"
   },
   "outputs": [],
   "source": [
    "x_in = Input(shape=(x_train.shape[1],x_train.shape[2]))\n",
    "x = Flatten()(x_in)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(x_in, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Amar6u-mEnL5"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=CategoricalCrossentropy(from_logits=False), optimizer=SGD(lr=1e-3, momentum=0.95), metrics=CategoricalAccuracy())\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6riUtq_EnPG",
    "outputId": "99ba9266-6882-4b85-d712-5b38979cee5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1013 - categorical_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10134784132242203, 0.9786999821662903]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5kPuNWeIwEO"
   },
   "outputs": [],
   "source": [
    "# model.save(path+'model_xxx/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxfHxe4nI7mY"
   },
   "outputs": [],
   "source": [
    "# model = load_model(path+'model_1200_1200_10_relu/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvVw44oiN4FC"
   },
   "source": [
    "## Data Perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExY8kMYKaF3B"
   },
   "source": [
    "**Main section for performing data perturbation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NgyKKf7tK6AV"
   },
   "outputs": [],
   "source": [
    "def objective(r, model, x, y, c=0.5, bayesian=False):\n",
    "    norm = tf.reduce_mean(tf.norm(r, axis=(1,2)))\n",
    "    perturbed_img = x + r\n",
    "    y_pred = model(perturbed_img)\n",
    "    loss_value = 1/c*CategoricalCrossentropy()(y, y_pred)\n",
    "\n",
    "    return (norm + loss_value)\n",
    "\n",
    "def perturb_data(model):\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    r_matrices = np.zeros((val_size, num_classes, img_shape1, img_shape2))\n",
    "    r_norms = np.zeros((val_size, num_classes))\n",
    "\n",
    "    for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
    "        for k in range(num_classes):\n",
    "            print('Class ' + str(k))\n",
    "            \n",
    "            r = tf.Variable(np.zeros((x_batch_val.shape[0], img_shape1, img_shape2))+2e-2, \n",
    "                            constraint = lambda x: tf.clip_by_value(x, 1e-6, 2.03 - x_batch_val),\n",
    "                            dtype=tf.float32, name='r')\n",
    "            y_fake = np.zeros((x_batch_val.shape[0], num_classes))\n",
    "            y_fake[:, k] = 1.\n",
    "        \n",
    "            epochs = 4000\n",
    "            for epoch in range(epochs):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    loss_value = objective(r, model, x_batch_val, y_fake, c=2*(epoch+1)/epochs)\n",
    "                    grads = tape.gradient(loss_value, [r])\n",
    "                optimizer.apply_gradients(zip(grads, [r]))\n",
    "\n",
    "                # y_pred = softmax(model(x_batch_val+r), axis=1)\n",
    "                # y_pred = y_pred.numpy()\n",
    "\n",
    "                if epoch % 100 == 0:\n",
    "                    print('Epoch ' + str(epoch))\n",
    "                    # count = 0\n",
    "                    # norm_count = 0\n",
    "                    # for i in range(x_batch_val.shape[0]):\n",
    "                    #     if np.argmax(y_pred[i,:]) == k and np.argmax(y_batch_val[i,:]) != k:\n",
    "                    #         count += 1\n",
    "                    #         norm_count += tf.norm(r[i]).numpy()\n",
    "                    # print(' -- Finding rate: ' + str(count/x_batch_val.shape[0]))\n",
    "                    # print(' -- Norm of r: ' + str(norm_count/x_batch_val.shape[0]))\n",
    "            \n",
    "            y_pred = model(x_batch_val+r).numpy()\n",
    "            \n",
    "            for j in range(x_batch_val.shape[0]):\n",
    "                i = int(step * batch_size + j)\n",
    "                if np.argmax(y_pred[i,:]) == k and np.argmax(y_batch_val[i,:]) != k:\n",
    "                    r_norms[i,k] = tf.norm(r[i]).numpy()\n",
    "                    r_matrices[i,k,:,:] = r[i].numpy()\n",
    "                else:\n",
    "                    r_norms[i,k] = 1e6\n",
    "                # print(r_norms[i,:])\n",
    "    return r_norms, r_matrices\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpddLCAEnro3"
   },
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jmten7-BTdTW"
   },
   "outputs": [],
   "source": [
    "model_names = ['model_10','model_10_l2_3','model_10_l2_2','model_10_l2_1',\n",
    "               'model_100_100_10_relu','model_100_100_10_relu_l2_3','model_100_100_10_relu_l2_2','model_100_100_10_relu_l2_1',\n",
    "               'model_200_200_10_relu','model_200_200_10_relu_l2_3','model_200_200_10_relu_l2_2','model_200_200_10_relu_l2_1',\n",
    "               'model_1200_1200_10_relu','model_1200_1200_10_relu_l2_3','model_1200_1200_10_relu_l2_2','model_1200_1200_10_relu_l2_1']\n",
    "\n",
    "bayes_names = ['bayes_30_0','bayes_10_0','bayes_4_0','bayes_3_0','bayes_2_5','bayes_2_0','bayes_1_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lS2CNWqDkowG"
   },
   "outputs": [],
   "source": [
    "for i in range(len(model_names)):\n",
    "    name = model_names[i]\n",
    "    model = load_model(path+'models/'+name+'/')\n",
    "    r_norms, r_matrices = perturb_data(model)\n",
    "    with open(path+'r_matrices/r_matrices_' + name + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(r_matrices, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBkD1Nk1nuCO"
   },
   "source": [
    "Get saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QngHSjfInLEA",
    "outputId": "16026272-d678-4542-f233-ae8ed99c9a1b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "r_matrices_16 = pd.read_pickle(path+'r_matrices/r_matrices_16.pickle')\n",
    "models = []\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    name = model_names[i]\n",
    "    models.append(load_model(path + 'models/' + name + '/'))\n",
    "    # r_matrices_16[i] = pd.read_pickle(path+'r_matrices/r_matrices_' + name + '.pickle')\n",
    "\n",
    "# with open(path+'r_matrices/r_matrices_16.pickle', 'wb') as handle:\n",
    "#     pickle.dump(r_matrices_16, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "bayes_models = []\n",
    "\n",
    "for i in range(len(bayes_names)):\n",
    "    name = bayes_names[i]\n",
    "    bayes_models.append(load_model(path + 'models/' + name + '/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FOUScQimbCJy"
   },
   "outputs": [],
   "source": [
    "r_norms = np.zeros((16, val_size, 10))\n",
    "for m in range(16):\n",
    "    for i in range(val_size):\n",
    "        for k in range(10):\n",
    "            r_norms[m,i,k] = np.linalg.norm(r_matrices_16[m,i,k,:,:])\n",
    "            if r_norms[m,i,k] == 0:\n",
    "                r_norms[m,i,k] = 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAzjFnZaZRjE"
   },
   "source": [
    "Below is how a model would classify a given example, and how it would classify the perturbed example. The example and its perturbed version are also illustrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+06 1.00000000e+06 1.00000000e+06 1.00000000e+06\n",
      " 1.00000000e+06 1.09895942e+00 1.00000000e+06 1.00000000e+06\n",
      " 1.00000000e+06 1.00000000e+06]\n"
     ]
    }
   ],
   "source": [
    "print(r_norms[0,0,:])\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8vxhpvvfwHt",
    "outputId": "32e5f6b6-3edb-4ad9-8a10-6680eff8c578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[3.2958287e-05, 8.7034367e-03, 6.6517822e-02, 8.8104618e-01,\n",
       "        4.1949020e-06, 1.5037716e-02, 7.5897301e-04, 8.7976968e-09,\n",
       "        2.7897265e-02, 1.4100091e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.expand_dims(x_val[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7er_360fzL4",
    "outputId": "797c7235-66b9-4803-b271-95e6b66beaa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[4.5227262e-05, 4.6922425e-03, 5.5727474e-02, 3.5146409e-01,\n",
       "        6.0429606e-06, 5.0984502e-01, 8.0185360e-04, 7.8982891e-09,\n",
       "        7.7416137e-02, 1.8884001e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.expand_dims(x_val[0]+r_matrices_16[0,0,5,:,:], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "MF1r4evGf3LL",
    "outputId": "6a3a788c-4845-4f24-b66b-8b48a9388bd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9887002c10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "DKw5knZAPkM6",
    "outputId": "560f07b0-54a0-4f07-c46e-936fd2fb1ded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9887e26150>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_val[0]+r_matrices_16[0,0,5,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "9wAgb-vchNIy"
   },
   "outputs": [],
   "source": [
    "def get_perturbations(m, multiplier=1):\n",
    "    y_perturbed = y_val.numpy()\n",
    "    x_perturbed = x_val.numpy()\n",
    "    remove_indices = []\n",
    "    distortion = 0\n",
    "    for i in range(val_size):\n",
    "        if sum(r_norms[m,i,:]) >= 1e7:\n",
    "            remove_indices.append(i)\n",
    "        else:\n",
    "            k = np.argmin(r_norms[m,i,:])\n",
    "            x_perturbed[i] = x_perturbed[i] + r_matrices_16[m,i,k,:,:]*multiplier\n",
    "            distortion += (np.sum(np.multiply(r_matrices_16[m,i,k,:,:], r_matrices_16[m,i,k,:,:]))/784)**0.5\n",
    "            \n",
    "    x_perturbed = np.delete(x_perturbed, remove_indices, axis=0)\n",
    "    y_perturbed = np.delete(y_perturbed, remove_indices, axis=0)\n",
    "    distortion = distortion / x_perturbed.shape[0]\n",
    "    return x_perturbed, y_perturbed, distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "id": "MSFSc1gR1pA_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_10\n",
      "(8351, 28, 28)\n",
      "0.0593779909460685\n",
      "---------------\n",
      "model_10_l2_3\n",
      "(7710, 28, 28)\n",
      "0.062148993435847295\n",
      "---------------\n",
      "model_10_l2_2\n",
      "(772, 28, 28)\n",
      "0.001316872849489344\n",
      "---------------\n",
      "model_10_l2_1\n",
      "(1117, 28, 28)\n",
      "0.0003831459854750663\n",
      "---------------\n",
      "model_100_100_10_relu\n",
      "(6895, 28, 28)\n",
      "0.05034573498653662\n",
      "---------------\n",
      "model_100_100_10_relu_l2_3\n",
      "(6748, 28, 28)\n",
      "0.04869280265941889\n",
      "---------------\n",
      "model_100_100_10_relu_l2_2\n",
      "(8929, 28, 28)\n",
      "0.07108349273440065\n",
      "---------------\n",
      "model_100_100_10_relu_l2_1\n",
      "(863, 28, 28)\n",
      "0.0005807538911293781\n",
      "---------------\n",
      "model_200_200_10_relu\n",
      "(7315, 28, 28)\n",
      "0.05568597814738444\n",
      "---------------\n",
      "model_200_200_10_relu_l2_3\n",
      "(7601, 28, 28)\n",
      "0.05613104089074708\n",
      "---------------\n",
      "model_200_200_10_relu_l2_2\n",
      "(8721, 28, 28)\n",
      "0.07419748740833922\n",
      "---------------\n",
      "model_200_200_10_relu_l2_1\n",
      "(669, 28, 28)\n",
      "0.0006460623718374734\n",
      "---------------\n",
      "model_1200_1200_10_relu\n",
      "(8248, 28, 28)\n",
      "0.06935490155309204\n",
      "---------------\n",
      "model_1200_1200_10_relu_l2_3\n",
      "(8248, 28, 28)\n",
      "0.0708185041912135\n",
      "---------------\n",
      "model_1200_1200_10_relu_l2_2\n",
      "(7867, 28, 28)\n",
      "0.08349892709064759\n",
      "---------------\n",
      "model_1200_1200_10_relu_l2_1\n",
      "(339, 28, 28)\n",
      "0.0008533637641142125\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "distortions = []\n",
    "for m in range(16):\n",
    "    x_perturbed, y_perturbed, distortion = get_perturbations(m)\n",
    "    distortions.append(distortion)\n",
    "    print(model_names[m])\n",
    "    print(x_perturbed.shape)\n",
    "    print(distortion)\n",
    "    print('---------------')\n",
    "np.savetxt('distortions.csv', np.array(distortions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for running Bayesian NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_BAYESIAN = load_model(path+'models/bayes_3_0/')\n",
    "'''\n",
    "When calling these functions, need to define global variable MODEL_BAYESIAN\n",
    "'''\n",
    "\n",
    "def call_model_bayesian(x, eval_samples=1, num_classes=num_classes):\n",
    "    pred_list = tf.constant(tf.zeros((1, x.shape[0], num_classes)))\n",
    "    pred_list, x_, s_, i_ = tf.while_loop(cond_eval_samples,\n",
    "                                        body_eval_samples, \n",
    "                                        loop_vars=[pred_list, x, \n",
    "                                                    eval_samples, 0],\n",
    "                                        shape_invariants=[tf.TensorShape([None, x.shape[0], num_classes]), \n",
    "                                                            x.shape,\n",
    "                                                            tf.TensorShape([]),\n",
    "                                                            tf.TensorShape([])])\n",
    "    pred_list = tf.gather(pred_list, list(range(1, eval_samples+1)))\n",
    "    pred_value = tf.reduce_mean(pred_list, axis=0)\n",
    "\n",
    "    return pred_value\n",
    "\n",
    "def evaluate_bayesian(x, y, eval_samples=1):\n",
    "    # 100/eval_samples had better be an integer\n",
    "    \n",
    "    metric = CategoricalAccuracy()\n",
    "    \n",
    "    acc_list = []\n",
    "    for s in range(int(100/eval_samples)):\n",
    "        pred_value = call_model_bayesian(x, eval_samples)\n",
    "        metric.update_state(y, pred_value)\n",
    "        acc = metric.result()\n",
    "        metric.reset_states()\n",
    "        acc_list.append(float(acc))\n",
    "        \n",
    "    accuracy = np.mean(acc_list)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def body_eval_samples(pred_list, x, eval_samples, i):\n",
    "    logits = MODEL_BAYESIAN(x)\n",
    "    pred_value = softmax(logits)\n",
    "    pred_list = tf.concat([pred_list, [pred_value]], axis=0)\n",
    "    i = i + 1\n",
    "    return pred_list, x, eval_samples, i\n",
    "\n",
    "def cond_eval_samples(pred_list, x, eval_samples, i):\n",
    "    return i < eval_samples\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "_xRUoSSeUimG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_10\n",
      "313/313 [==============================] - 0s 865us/step - loss: 0.2585 - categorical_accuracy: 0.9310\n",
      "model_10_l2_3\n",
      "313/313 [==============================] - 0s 713us/step - loss: 0.2607 - categorical_accuracy: 0.9298\n",
      "model_10_l2_2\n",
      "313/313 [==============================] - 0s 861us/step - loss: 0.3084 - categorical_accuracy: 0.9267\n",
      "model_10_l2_1\n",
      "313/313 [==============================] - 0s 993us/step - loss: 0.8538 - categorical_accuracy: 0.8891\n",
      "model_100_100_10_relu\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0969 - categorical_accuracy: 0.9757\n",
      "model_100_100_10_relu_l2_3\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1067 - categorical_accuracy: 0.9762\n",
      "model_100_100_10_relu_l2_2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1279 - categorical_accuracy: 0.9780\n",
      "model_100_100_10_relu_l2_1\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.8775 - categorical_accuracy: 0.9144\n",
      "model_200_200_10_relu\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0925 - categorical_accuracy: 0.9791\n",
      "model_200_200_10_relu_l2_3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0859 - categorical_accuracy: 0.9785\n",
      "model_200_200_10_relu_l2_2\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1136 - categorical_accuracy: 0.9810\n",
      "model_200_200_10_relu_l2_1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6752 - categorical_accuracy: 0.9337\n",
      "model_1200_1200_10_relu\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0738 - categorical_accuracy: 0.9811\n",
      "model_1200_1200_10_relu_l2_3\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0753 - categorical_accuracy: 0.9809\n",
      "model_1200_1200_10_relu_l2_2\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0992 - categorical_accuracy: 0.9820\n",
      "model_1200_1200_10_relu_l2_1\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3891 - categorical_accuracy: 0.9671\n",
      "Bayesian NN validation accuracy: 0.9751\n",
      "Bayesian NN validation accuracy: 0.9728\n",
      "Bayesian NN validation accuracy: 0.9743\n",
      "Bayesian NN validation accuracy: 0.9724\n",
      "Bayesian NN validation accuracy: 0.9673\n",
      "Bayesian NN validation accuracy: 0.9622\n",
      "Bayesian NN validation accuracy: 0.9505\n"
     ]
    }
   ],
   "source": [
    "val_acc = []\n",
    "for m in range(16):\n",
    "    print(model_names[m])\n",
    "    lst = models[m].evaluate(x_val, y_val)\n",
    "    val_acc.append(lst[1])\n",
    "for m in range(len(bayes_models)):\n",
    "    MODEL_BAYESIAN = bayes_models[m]\n",
    "    acc = evaluate_bayesian(x_val, y_val)\n",
    "    val_acc.append(acc)\n",
    "    print(\"Bayesian NN validation accuracy: %.4f\" % (acc,))\n",
    "    \n",
    "np.savetxt('val_acc.csv', np.array(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_10\n",
      "313/313 [==============================] - 0s 904us/step - loss: 0.2670 - categorical_accuracy: 0.9261\n",
      "model_10_l2_3\n",
      "313/313 [==============================] - 0s 788us/step - loss: 0.2685 - categorical_accuracy: 0.9258\n",
      "model_10_l2_2\n",
      "313/313 [==============================] - 0s 791us/step - loss: 0.3165 - categorical_accuracy: 0.9234\n",
      "model_10_l2_1\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.8650 - categorical_accuracy: 0.8875\n",
      "model_100_100_10_relu\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0954 - categorical_accuracy: 0.9757\n",
      "model_100_100_10_relu_l2_3\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0994 - categorical_accuracy: 0.9764\n",
      "model_100_100_10_relu_l2_2\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1196 - categorical_accuracy: 0.9794\n",
      "model_100_100_10_relu_l2_1\n",
      "313/313 [==============================] - 0s 951us/step - loss: 0.8847 - categorical_accuracy: 0.9091\n",
      "model_200_200_10_relu\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0849 - categorical_accuracy: 0.9779\n",
      "model_200_200_10_relu_l2_3\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0828 - categorical_accuracy: 0.9788\n",
      "model_200_200_10_relu_l2_2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1069 - categorical_accuracy: 0.9796\n",
      "model_200_200_10_relu_l2_1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6833 - categorical_accuracy: 0.9295: 0s - loss: 0.7115 - cate\n",
      "model_1200_1200_10_relu\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0658 - categorical_accuracy: 0.9809\n",
      "model_1200_1200_10_relu_l2_3\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0645 - categorical_accuracy: 0.9815\n",
      "model_1200_1200_10_relu_l2_2\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0933 - categorical_accuracy: 0.9823\n",
      "model_1200_1200_10_relu_l2_1\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3907 - categorical_accuracy: 0.9640\n",
      "Bayesian NN test accuracy: 0.9751\n",
      "Bayesian NN test accuracy: 0.9746\n",
      "Bayesian NN test accuracy: 0.9737\n",
      "Bayesian NN test accuracy: 0.9712\n",
      "Bayesian NN test accuracy: 0.9661\n",
      "Bayesian NN test accuracy: 0.9611\n",
      "Bayesian NN test accuracy: 0.9459\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "for m in range(16):\n",
    "    print(model_names[m])\n",
    "    lst = models[m].evaluate(x_test, y_test)\n",
    "    test_acc.append(lst[1])\n",
    "for m in range(len(bayes_models)):\n",
    "    MODEL_BAYESIAN = bayes_models[m]\n",
    "    acc = evaluate_bayesian(x_test, y_test)\n",
    "    test_acc.append(acc)\n",
    "    print(\"Bayesian NN test accuracy: %.4f\" % (acc,))\n",
    "    \n",
    "np.savetxt('test_acc.csv', np.array(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on Perturbed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "id": "i-HK61X5YzeC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_10\n",
      "261/261 [==============================] - 0s 750us/step - loss: 14.5458 - categorical_accuracy: 0.0000e+00\n",
      "261/261 [==============================] - 0s 947us/step - loss: 12.3387 - categorical_accuracy: 0.0000e+00\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 4.6324 - categorical_accuracy: 0.0115\n",
      "261/261 [==============================] - 0s 827us/step - loss: 1.1739 - categorical_accuracy: 0.8025\n",
      "261/261 [==============================] - 1s 3ms/step - loss: 3.3140 - categorical_accuracy: 0.4568\n",
      "261/261 [==============================] - 2s 6ms/step - loss: 2.9384 - categorical_accuracy: 0.4774\n",
      "261/261 [==============================] - 1s 5ms/step - loss: 2.4758 - categorical_accuracy: 0.4858\n",
      "261/261 [==============================] - 1s 5ms/step - loss: 1.0751 - categorical_accuracy: 0.7000\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 3.4353 - categorical_accuracy: 0.4895\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 3.7212 - categorical_accuracy: 0.4487\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 2.4911 - categorical_accuracy: 0.5072\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 1.1333 - categorical_accuracy: 0.7869\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 4.1683 - categorical_accuracy: 0.4677\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 5.5101 - categorical_accuracy: 0.3748\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 3.1435 - categorical_accuracy: 0.4183\n",
      "261/261 [==============================] - 0s 1ms/step - loss: 1.3326 - categorical_accuracy: 0.7682\n",
      "model_10_l2_3\n",
      "241/241 [==============================] - 0s 782us/step - loss: 14.2237 - categorical_accuracy: 1.2970e-04\n",
      "241/241 [==============================] - 0s 797us/step - loss: 14.6473 - categorical_accuracy: 0.0000e+00\n",
      "241/241 [==============================] - 0s 785us/step - loss: 5.1973 - categorical_accuracy: 0.0109\n",
      "241/241 [==============================] - 0s 800us/step - loss: 1.2108 - categorical_accuracy: 0.7878\n",
      "241/241 [==============================] - 1s 4ms/step - loss: 3.8589 - categorical_accuracy: 0.4191\n",
      "241/241 [==============================] - 1s 5ms/step - loss: 3.4892 - categorical_accuracy: 0.4311\n",
      "241/241 [==============================] - 1s 5ms/step - loss: 2.9597 - categorical_accuracy: 0.4367\n",
      "241/241 [==============================] - 1s 5ms/step - loss: 1.2541 - categorical_accuracy: 0.6358\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4.2366 - categorical_accuracy: 0.4314\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4.4355 - categorical_accuracy: 0.4048\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2.8855 - categorical_accuracy: 0.4681\n",
      "241/241 [==============================] - 1s 3ms/step - loss: 1.2261 - categorical_accuracy: 0.7482\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4.7259 - categorical_accuracy: 0.4306\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 6.3840 - categorical_accuracy: 0.3375\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3.6747 - categorical_accuracy: 0.3754\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 1.4205 - categorical_accuracy: 0.7274\n",
      "model_10_l2_2\n",
      "25/25 [==============================] - 0s 817us/step - loss: 2.6115 - categorical_accuracy: 0.1088\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.6064 - categorical_accuracy: 0.0972\n",
      "25/25 [==============================] - 0s 798us/step - loss: 2.4359 - categorical_accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.2401 - categorical_accuracy: 0.1464\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8143 - categorical_accuracy: 0.7979\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8431 - categorical_accuracy: 0.7940\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7673 - categorical_accuracy: 0.8031\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3869 - categorical_accuracy: 0.5894\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.0082 - categorical_accuracy: 0.7953\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9040 - categorical_accuracy: 0.7863\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8005 - categorical_accuracy: 0.8005\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.0790 - categorical_accuracy: 0.3070\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9971 - categorical_accuracy: 0.7733\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1313 - categorical_accuracy: 0.7668\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8934 - categorical_accuracy: 0.7785\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.3957 - categorical_accuracy: 0.2137\n",
      "model_10_l2_1\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.7146 - categorical_accuracy: 0.4996\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7213 - categorical_accuracy: 0.4888\n",
      "35/35 [==============================] - 0s 905us/step - loss: 1.7278 - categorical_accuracy: 0.4306\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.1489 - categorical_accuracy: 0.0000e+00\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5565 - categorical_accuracy: 0.8657\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5767 - categorical_accuracy: 0.8630\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5289 - categorical_accuracy: 0.8684\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 1.0830 - categorical_accuracy: 0.7278\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6901 - categorical_accuracy: 0.8559\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6150 - categorical_accuracy: 0.8532\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5674 - categorical_accuracy: 0.8612\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.7759 - categorical_accuracy: 0.4727\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6871 - categorical_accuracy: 0.8451\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7667 - categorical_accuracy: 0.8451\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6284 - categorical_accuracy: 0.8496\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.1308 - categorical_accuracy: 0.3384\n",
      "model_1200_1200_10_relu\n",
      "258/258 [==============================] - 0s 774us/step - loss: 7.1290 - categorical_accuracy: 0.0234\n",
      "258/258 [==============================] - 0s 888us/step - loss: 6.7014 - categorical_accuracy: 0.0268\n",
      "258/258 [==============================] - 0s 885us/step - loss: 2.8301 - categorical_accuracy: 0.1215\n",
      "258/258 [==============================] - 0s 878us/step - loss: 1.2981 - categorical_accuracy: 0.6883\n",
      "258/258 [==============================] - 1s 4ms/step - loss: 21.1390 - categorical_accuracy: 0.0000e+00\n",
      "258/258 [==============================] - 1s 5ms/step - loss: 8.7043 - categorical_accuracy: 0.0145\n",
      "258/258 [==============================] - 1s 5ms/step - loss: 7.2892 - categorical_accuracy: 0.0164\n",
      "258/258 [==============================] - 1s 6ms/step - loss: 1.7197 - categorical_accuracy: 0.3278\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 11.2350 - categorical_accuracy: 0.0195\n",
      "258/258 [==============================] - 0s 2ms/step - loss: 11.1008 - categorical_accuracy: 0.0226\n",
      "258/258 [==============================] - 1s 2ms/step - loss: 7.8669 - categorical_accuracy: 0.0241: 0s - loss: 7.8056 - categorical_accu\n",
      "258/258 [==============================] - 1s 2ms/step - loss: 1.3687 - categorical_accuracy: 0.6000\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 12.2822 - categorical_accuracy: 0.0246\n",
      "258/258 [==============================] - 1s 2ms/step - loss: 13.5032 - categorical_accuracy: 0.0227 ETA: 0s - loss: 13.3542 - categorical_accuracy\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 8.2862 - categorical_accuracy: 0.0247\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 1.4860 - categorical_accuracy: 0.6216\n",
      "model_1200_1200_10_relu_l2_3\n",
      "258/258 [==============================] - 0s 767us/step - loss: 7.2237 - categorical_accuracy: 0.0241\n",
      "258/258 [==============================] - 0s 752us/step - loss: 6.7309 - categorical_accuracy: 0.0264\n",
      "258/258 [==============================] - 0s 858us/step - loss: 2.8860 - categorical_accuracy: 0.1199\n",
      "258/258 [==============================] - 0s 759us/step - loss: 1.3107 - categorical_accuracy: 0.6845\n",
      "258/258 [==============================] - 1s 3ms/step - loss: 9.4310 - categorical_accuracy: 0.0102\n",
      "258/258 [==============================] - 1s 5ms/step - loss: 21.1786 - categorical_accuracy: 0.0000e+00\n",
      "258/258 [==============================] - 1s 5ms/step - loss: 7.6947 - categorical_accuracy: 0.0115\n",
      "258/258 [==============================] - 1s 5ms/step - loss: 1.7649 - categorical_accuracy: 0.3082\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 11.5706 - categorical_accuracy: 0.0171\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 11.4862 - categorical_accuracy: 0.0179\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 8.0734 - categorical_accuracy: 0.0228\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 1.3929 - categorical_accuracy: 0.5820\n",
      "258/258 [==============================] - 0s 2ms/step - loss: 12.5557 - categorical_accuracy: 0.0204\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 14.1166 - categorical_accuracy: 0.0198\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 8.5268 - categorical_accuracy: 0.0226\n",
      "258/258 [==============================] - 0s 1ms/step - loss: 1.5052 - categorical_accuracy: 0.6130\n",
      "model_1200_1200_10_relu_l2_2\n",
      "246/246 [==============================] - 0s 771us/step - loss: 10.3368 - categorical_accuracy: 0.0107\n",
      "246/246 [==============================] - 0s 735us/step - loss: 9.7230 - categorical_accuracy: 0.0114\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4.3083 - categorical_accuracy: 0.0470: 0s - loss: 4.3474 - categorical_accuracy\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 1.4597 - categorical_accuracy: 0.5923\n",
      "246/246 [==============================] - 2s 6ms/step - loss: 14.9974 - categorical_accuracy: 0.0053\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 14.9037 - categorical_accuracy: 0.0046\n",
      "246/246 [==============================] - 2s 6ms/step - loss: 19.9194 - categorical_accuracy: 0.0000e+00\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 3.0321 - categorical_accuracy: 0.0803\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 18.5105 - categorical_accuracy: 0.0080\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 18.0834 - categorical_accuracy: 0.0075\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 13.0584 - categorical_accuracy: 0.0083\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 1.8505 - categorical_accuracy: 0.3707\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 20.1731 - categorical_accuracy: 0.0086\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 22.0900 - categorical_accuracy: 0.0078\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 13.8555 - categorical_accuracy: 0.0086\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 1.8524 - categorical_accuracy: 0.4286\n",
      "model_1200_1200_10_relu_l2_1\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.6653 - categorical_accuracy: 0.1239\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.6673 - categorical_accuracy: 0.1121\n",
      "11/11 [==============================] - 0s 938us/step - loss: 3.3106 - categorical_accuracy: 0.0885\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.5937 - categorical_accuracy: 0.0914\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8613 - categorical_accuracy: 0.5398\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9088 - categorical_accuracy: 0.5487\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6585 - categorical_accuracy: 0.5634\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.3684 - categorical_accuracy: 0.0000e+00\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.2801 - categorical_accuracy: 0.5339\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.0365 - categorical_accuracy: 0.5428\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.7480 - categorical_accuracy: 0.5428\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.8442 - categorical_accuracy: 0.0796\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.2488 - categorical_accuracy: 0.5192\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.5064 - categorical_accuracy: 0.5074\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8620 - categorical_accuracy: 0.5369\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.9578 - categorical_accuracy: 0.0944\n",
      "model_200_200_10_relu\n",
      "229/229 [==============================] - 0s 920us/step - loss: 3.8009 - categorical_accuracy: 0.0968\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 3.6369 - categorical_accuracy: 0.1021\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 1.5918 - categorical_accuracy: 0.3907\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 1.2183 - categorical_accuracy: 0.7461\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 4.1917 - categorical_accuracy: 0.1277\n",
      "229/229 [==============================] - 2s 7ms/step - loss: 3.8768 - categorical_accuracy: 0.1398\n",
      "229/229 [==============================] - 2s 7ms/step - loss: 3.3141 - categorical_accuracy: 0.1429\n",
      "229/229 [==============================] - 2s 8ms/step - loss: 1.0697 - categorical_accuracy: 0.6461\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 22.3473 - categorical_accuracy: 0.0000e+00\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 5.1176 - categorical_accuracy: 0.1435\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 3.7453 - categorical_accuracy: 0.1444: 0s - loss: 3.7575 - categorical_accura\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 1.1470 - categorical_accuracy: 0.7348\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 6.3980 - categorical_accuracy: 0.1351\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 6.9037 - categorical_accuracy: 0.1233\n",
      "229/229 [==============================] - 0s 2ms/step - loss: 4.2169 - categorical_accuracy: 0.1217\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 1.3290 - categorical_accuracy: 0.7244\n",
      "model_200_200_10_relu_l2_3\n",
      "238/238 [==============================] - 0s 782us/step - loss: 3.7535 - categorical_accuracy: 0.1145\n",
      "238/238 [==============================] - 0s 978us/step - loss: 3.5368 - categorical_accuracy: 0.1200\n",
      "238/238 [==============================] - 0s 803us/step - loss: 1.5291 - categorical_accuracy: 0.4017\n",
      "238/238 [==============================] - 0s 784us/step - loss: 1.1906 - categorical_accuracy: 0.7654\n",
      "238/238 [==============================] - 1s 4ms/step - loss: 3.9578 - categorical_accuracy: 0.1235\n",
      "238/238 [==============================] - 1s 6ms/step - loss: 3.7326 - categorical_accuracy: 0.1530\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 3.1204 - categorical_accuracy: 0.1551\n",
      "238/238 [==============================] - 1s 5ms/step - loss: 1.0088 - categorical_accuracy: 0.6762\n",
      "238/238 [==============================] - 0s 1ms/step - loss: 4.9055 - categorical_accuracy: 0.1431\n",
      "238/238 [==============================] - 0s 1ms/step - loss: 21.8589 - categorical_accuracy: 0.0000e+00\n",
      "238/238 [==============================] - 0s 2ms/step - loss: 3.6202 - categorical_accuracy: 0.1450\n",
      "238/238 [==============================] - 0s 2ms/step - loss: 1.1074 - categorical_accuracy: 0.7604\n",
      "238/238 [==============================] - 0s 1ms/step - loss: 5.7695 - categorical_accuracy: 0.1477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 0s 1ms/step - loss: 6.7633 - categorical_accuracy: 0.1122\n",
      "238/238 [==============================] - 0s 1ms/step - loss: 3.8805 - categorical_accuracy: 0.1433\n",
      "238/238 [==============================] - 0s 2ms/step - loss: 1.2885 - categorical_accuracy: 0.7431\n",
      "model_200_200_10_relu_l2_2\n",
      "273/273 [==============================] - 0s 986us/step - loss: 7.2051 - categorical_accuracy: 0.0230\n",
      "273/273 [==============================] - 0s 921us/step - loss: 6.8183 - categorical_accuracy: 0.0241\n",
      "273/273 [==============================] - 0s 896us/step - loss: 2.9031 - categorical_accuracy: 0.1501\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 1.3127 - categorical_accuracy: 0.6860\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 10.0946 - categorical_accuracy: 0.0149\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 9.5592 - categorical_accuracy: 0.0166\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 8.0216 - categorical_accuracy: 0.0177\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 1.9292 - categorical_accuracy: 0.3020\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 12.6447 - categorical_accuracy: 0.0180\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 12.4918 - categorical_accuracy: 0.0177\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 19.0890 - categorical_accuracy: 0.0000e+00\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 1.4339 - categorical_accuracy: 0.5644\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 14.2495 - categorical_accuracy: 0.0169\n",
      "273/273 [==============================] - 0s 1ms/step - loss: 15.1153 - categorical_accuracy: 0.0206\n",
      "273/273 [==============================] - 1s 2ms/step - loss: 9.7801 - categorical_accuracy: 0.0175\n",
      "273/273 [==============================] - 0s 2ms/step - loss: 1.5382 - categorical_accuracy: 0.6003\n",
      "model_200_200_10_relu_l2_1\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.4759 - categorical_accuracy: 0.3094\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.4823 - categorical_accuracy: 0.2990\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 2.4048 - categorical_accuracy: 0.2212\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 2.3399 - categorical_accuracy: 0.1181\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.9236 - categorical_accuracy: 0.7728\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9520 - categorical_accuracy: 0.7743\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.8506 - categorical_accuracy: 0.7803\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.5206 - categorical_accuracy: 0.5336\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1258 - categorical_accuracy: 0.7758\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0091 - categorical_accuracy: 0.7683\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8952 - categorical_accuracy: 0.7788\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.3544 - categorical_accuracy: 0.0000e+00\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1179 - categorical_accuracy: 0.7459\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2922 - categorical_accuracy: 0.7444\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9891 - categorical_accuracy: 0.7549\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.6168 - categorical_accuracy: 0.0747\n",
      "model_100_100_10_relu\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 3.1149 - categorical_accuracy: 0.1590\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 2.8715 - categorical_accuracy: 0.1793\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 1.3427 - categorical_accuracy: 0.5063\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 1.1947 - categorical_accuracy: 0.7626\n",
      "216/216 [==============================] - 1s 4ms/step - loss: 2.7393 - categorical_accuracy: 0.2490\n",
      "216/216 [==============================] - 1s 6ms/step - loss: 2.4824 - categorical_accuracy: 0.2850\n",
      "216/216 [==============================] - 2s 8ms/step - loss: 2.1952 - categorical_accuracy: 0.2734\n",
      "216/216 [==============================] - 2s 7ms/step - loss: 0.9207 - categorical_accuracy: 0.7372\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3.8111 - categorical_accuracy: 0.2132\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3.5150 - categorical_accuracy: 0.2371\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 2.6266 - categorical_accuracy: 0.2531\n",
      "216/216 [==============================] - 1s 2ms/step - loss: 1.0846 - categorical_accuracy: 0.7761\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 22.1884 - categorical_accuracy: 0.0000e+00\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 4.9140 - categorical_accuracy: 0.1994\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 2.9145 - categorical_accuracy: 0.2126\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 1.2785 - categorical_accuracy: 0.7530\n",
      "model_100_100_10_relu_l2_3\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 3.1876 - categorical_accuracy: 0.1598\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 2.9533 - categorical_accuracy: 0.1774\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 1.3431 - categorical_accuracy: 0.4947\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 1.1907 - categorical_accuracy: 0.7608\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 2.6036 - categorical_accuracy: 0.2699\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 2.4490 - categorical_accuracy: 0.3031\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 2.1198 - categorical_accuracy: 0.2956\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 0.8970 - categorical_accuracy: 0.7451\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 3.4573 - categorical_accuracy: 0.2501\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 3.6033 - categorical_accuracy: 0.2416\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 2.4034 - categorical_accuracy: 0.2927\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 1.0734 - categorical_accuracy: 0.7792\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 4.1452 - categorical_accuracy: 0.2580\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 22.9515 - categorical_accuracy: 0.0000e+00\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 2.7671 - categorical_accuracy: 0.2522\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 1.2708 - categorical_accuracy: 0.7558\n",
      "model_100_100_10_relu_l2_2\n",
      "280/280 [==============================] - 0s 945us/step - loss: 7.0906 - categorical_accuracy: 0.0315\n",
      "280/280 [==============================] - 0s 983us/step - loss: 6.6276 - categorical_accuracy: 0.0340\n",
      "280/280 [==============================] - 0s 2ms/step - loss: 2.8159 - categorical_accuracy: 0.1634\n",
      "280/280 [==============================] - 0s 2ms/step - loss: 1.2737 - categorical_accuracy: 0.7084\n",
      "280/280 [==============================] - 1s 5ms/step - loss: 8.8104 - categorical_accuracy: 0.0319\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 8.5033 - categorical_accuracy: 0.0381\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 7.3162 - categorical_accuracy: 0.0329\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 1.7751 - categorical_accuracy: 0.3362\n",
      "280/280 [==============================] - 0s 1ms/step - loss: 11.6445 - categorical_accuracy: 0.0299\n",
      "280/280 [==============================] - 0s 2ms/step - loss: 10.8195 - categorical_accuracy: 0.0405\n",
      "280/280 [==============================] - 0s 2ms/step - loss: 8.3006 - categorical_accuracy: 0.0372\n",
      "280/280 [==============================] - 0s 2ms/step - loss: 1.3716 - categorical_accuracy: 0.6093\n",
      "280/280 [==============================] - 0s 1ms/step - loss: 12.3526 - categorical_accuracy: 0.0367\n",
      "280/280 [==============================] - 0s 2ms/step - loss: 13.6585 - categorical_accuracy: 0.0396\n",
      "280/280 [==============================] - 0s 1ms/step - loss: 18.4450 - categorical_accuracy: 0.0000e+00\n",
      "280/280 [==============================] - 0s 2ms/step - loss: 1.4877 - categorical_accuracy: 0.6182\n",
      "model_100_100_10_relu_l2_1\n",
      "27/27 [==============================] - 0s 933us/step - loss: 2.0734 - categorical_accuracy: 0.3986\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 2.0751 - categorical_accuracy: 0.3812\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.0554 - categorical_accuracy: 0.3140\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.2197 - categorical_accuracy: 0.1448\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.7093 - categorical_accuracy: 0.8308\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.7263 - categorical_accuracy: 0.8331\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.6650 - categorical_accuracy: 0.8378\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.2719 - categorical_accuracy: 0.6477\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8719 - categorical_accuracy: 0.8181\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7833 - categorical_accuracy: 0.8204\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7020 - categorical_accuracy: 0.8320\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 2.0545 - categorical_accuracy: 0.2781\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8800 - categorical_accuracy: 0.7995\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9981 - categorical_accuracy: 0.8019\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7708 - categorical_accuracy: 0.8123\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 2.4475 - categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "multiplier = 3\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['names'] = model_names\n",
    "distortion_list = []\n",
    "for i in range(16):\n",
    "    df[model_names[i]] = 0.\n",
    "for i in range(16):\n",
    "    print(model_names[i])\n",
    "    x_perturbed, y_perturbed, distortion = get_perturbations(i, multiplier)\n",
    "    distortion_list.append(distortion)\n",
    "    for j in range(16):\n",
    "        lst = models[j].evaluate(x_perturbed, y_perturbed)\n",
    "        df.iloc[i, j+1] = lst[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>model_10</th>\n",
       "      <th>model_10_l2_3</th>\n",
       "      <th>model_10_l2_2</th>\n",
       "      <th>model_10_l2_1</th>\n",
       "      <th>model_1200_1200_10_relu</th>\n",
       "      <th>model_1200_1200_10_relu_l2_3</th>\n",
       "      <th>model_1200_1200_10_relu_l2_2</th>\n",
       "      <th>model_1200_1200_10_relu_l2_1</th>\n",
       "      <th>model_200_200_10_relu</th>\n",
       "      <th>model_200_200_10_relu_l2_3</th>\n",
       "      <th>model_200_200_10_relu_l2_2</th>\n",
       "      <th>model_200_200_10_relu_l2_1</th>\n",
       "      <th>model_100_100_10_relu</th>\n",
       "      <th>model_100_100_10_relu_l2_3</th>\n",
       "      <th>model_100_100_10_relu_l2_2</th>\n",
       "      <th>model_100_100_10_relu_l2_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>0.802539</td>\n",
       "      <td>0.456832</td>\n",
       "      <td>0.477428</td>\n",
       "      <td>0.485810</td>\n",
       "      <td>0.700036</td>\n",
       "      <td>0.489522</td>\n",
       "      <td>0.448689</td>\n",
       "      <td>0.507245</td>\n",
       "      <td>0.786852</td>\n",
       "      <td>0.467728</td>\n",
       "      <td>0.374805</td>\n",
       "      <td>0.418273</td>\n",
       "      <td>0.768171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>model_10_l2_3</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.787808</td>\n",
       "      <td>0.419066</td>\n",
       "      <td>0.431128</td>\n",
       "      <td>0.436706</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.431388</td>\n",
       "      <td>0.404799</td>\n",
       "      <td>0.468093</td>\n",
       "      <td>0.748249</td>\n",
       "      <td>0.430610</td>\n",
       "      <td>0.337484</td>\n",
       "      <td>0.375357</td>\n",
       "      <td>0.727367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>model_10_l2_2</td>\n",
       "      <td>0.108808</td>\n",
       "      <td>0.097150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146373</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.794041</td>\n",
       "      <td>0.803109</td>\n",
       "      <td>0.589378</td>\n",
       "      <td>0.795337</td>\n",
       "      <td>0.786269</td>\n",
       "      <td>0.800518</td>\n",
       "      <td>0.306995</td>\n",
       "      <td>0.773316</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.778497</td>\n",
       "      <td>0.213731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>model_10_l2_1</td>\n",
       "      <td>0.499552</td>\n",
       "      <td>0.488809</td>\n",
       "      <td>0.430618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865712</td>\n",
       "      <td>0.863026</td>\n",
       "      <td>0.868397</td>\n",
       "      <td>0.727842</td>\n",
       "      <td>0.855864</td>\n",
       "      <td>0.853178</td>\n",
       "      <td>0.861235</td>\n",
       "      <td>0.472695</td>\n",
       "      <td>0.845121</td>\n",
       "      <td>0.845121</td>\n",
       "      <td>0.849597</td>\n",
       "      <td>0.338406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>model_1200_1200_10_relu</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.026794</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.688288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.327837</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.600024</td>\n",
       "      <td>0.024612</td>\n",
       "      <td>0.022672</td>\n",
       "      <td>0.024733</td>\n",
       "      <td>0.621605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>model_1200_1200_10_relu_l2_3</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.119908</td>\n",
       "      <td>0.684530</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>0.308196</td>\n",
       "      <td>0.017095</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.022793</td>\n",
       "      <td>0.581959</td>\n",
       "      <td>0.020369</td>\n",
       "      <td>0.019762</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.612997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>model_1200_1200_10_relu_l2_2</td>\n",
       "      <td>0.010678</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.047032</td>\n",
       "      <td>0.592348</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>0.370662</td>\n",
       "      <td>0.008644</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>0.008644</td>\n",
       "      <td>0.428626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>model_1200_1200_10_relu_l2_1</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.112094</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.091445</td>\n",
       "      <td>0.539823</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>0.563422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533923</td>\n",
       "      <td>0.542773</td>\n",
       "      <td>0.542773</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.519174</td>\n",
       "      <td>0.507375</td>\n",
       "      <td>0.536873</td>\n",
       "      <td>0.094395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>model_200_200_10_relu</td>\n",
       "      <td>0.096787</td>\n",
       "      <td>0.102119</td>\n",
       "      <td>0.390704</td>\n",
       "      <td>0.746138</td>\n",
       "      <td>0.127683</td>\n",
       "      <td>0.139850</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.646070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143541</td>\n",
       "      <td>0.144361</td>\n",
       "      <td>0.734792</td>\n",
       "      <td>0.135065</td>\n",
       "      <td>0.123308</td>\n",
       "      <td>0.121668</td>\n",
       "      <td>0.724402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>model_200_200_10_relu_l2_3</td>\n",
       "      <td>0.114459</td>\n",
       "      <td>0.119984</td>\n",
       "      <td>0.401658</td>\n",
       "      <td>0.765426</td>\n",
       "      <td>0.123536</td>\n",
       "      <td>0.153006</td>\n",
       "      <td>0.155111</td>\n",
       "      <td>0.676227</td>\n",
       "      <td>0.143139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144981</td>\n",
       "      <td>0.760426</td>\n",
       "      <td>0.147744</td>\n",
       "      <td>0.112222</td>\n",
       "      <td>0.143271</td>\n",
       "      <td>0.743060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>model_200_200_10_relu_l2_2</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>0.150097</td>\n",
       "      <td>0.686045</td>\n",
       "      <td>0.014907</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>0.302030</td>\n",
       "      <td>0.018003</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564385</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>0.020640</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.600275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>model_200_200_10_relu_l2_1</td>\n",
       "      <td>0.309417</td>\n",
       "      <td>0.298954</td>\n",
       "      <td>0.221226</td>\n",
       "      <td>0.118087</td>\n",
       "      <td>0.772795</td>\n",
       "      <td>0.774290</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>0.533632</td>\n",
       "      <td>0.775785</td>\n",
       "      <td>0.768311</td>\n",
       "      <td>0.778774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745889</td>\n",
       "      <td>0.744395</td>\n",
       "      <td>0.754858</td>\n",
       "      <td>0.074738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>model_100_100_10_relu</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>0.179260</td>\n",
       "      <td>0.506309</td>\n",
       "      <td>0.762582</td>\n",
       "      <td>0.249021</td>\n",
       "      <td>0.284989</td>\n",
       "      <td>0.273387</td>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.213198</td>\n",
       "      <td>0.237128</td>\n",
       "      <td>0.253082</td>\n",
       "      <td>0.776070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199420</td>\n",
       "      <td>0.212618</td>\n",
       "      <td>0.753009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>model_100_100_10_relu_l2_3</td>\n",
       "      <td>0.159751</td>\n",
       "      <td>0.177386</td>\n",
       "      <td>0.494665</td>\n",
       "      <td>0.760818</td>\n",
       "      <td>0.269858</td>\n",
       "      <td>0.303053</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>0.745110</td>\n",
       "      <td>0.250148</td>\n",
       "      <td>0.241553</td>\n",
       "      <td>0.292679</td>\n",
       "      <td>0.779194</td>\n",
       "      <td>0.258002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252223</td>\n",
       "      <td>0.755780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>model_100_100_10_relu_l2_2</td>\n",
       "      <td>0.031470</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.708366</td>\n",
       "      <td>0.031918</td>\n",
       "      <td>0.038078</td>\n",
       "      <td>0.032926</td>\n",
       "      <td>0.336208</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.040542</td>\n",
       "      <td>0.037182</td>\n",
       "      <td>0.609251</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.039646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.618210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>model_100_100_10_relu_l2_1</td>\n",
       "      <td>0.398609</td>\n",
       "      <td>0.381228</td>\n",
       "      <td>0.314021</td>\n",
       "      <td>0.144844</td>\n",
       "      <td>0.830823</td>\n",
       "      <td>0.833140</td>\n",
       "      <td>0.837775</td>\n",
       "      <td>0.647740</td>\n",
       "      <td>0.818076</td>\n",
       "      <td>0.820394</td>\n",
       "      <td>0.831981</td>\n",
       "      <td>0.278100</td>\n",
       "      <td>0.799537</td>\n",
       "      <td>0.801854</td>\n",
       "      <td>0.812283</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           names  model_10  model_10_l2_3  model_10_l2_2  \\\n",
       "0                       model_10  0.000000       0.000000       0.011496   \n",
       "1                  model_10_l2_3  0.000130       0.000000       0.010895   \n",
       "2                  model_10_l2_2  0.108808       0.097150       0.000000   \n",
       "3                  model_10_l2_1  0.499552       0.488809       0.430618   \n",
       "4        model_1200_1200_10_relu  0.023400       0.026794       0.121484   \n",
       "5   model_1200_1200_10_relu_l2_3  0.024127       0.026431       0.119908   \n",
       "6   model_1200_1200_10_relu_l2_2  0.010678       0.011440       0.047032   \n",
       "7   model_1200_1200_10_relu_l2_1  0.123894       0.112094       0.088496   \n",
       "8          model_200_200_10_relu  0.096787       0.102119       0.390704   \n",
       "9     model_200_200_10_relu_l2_3  0.114459       0.119984       0.401658   \n",
       "10    model_200_200_10_relu_l2_2  0.023048       0.024080       0.150097   \n",
       "11    model_200_200_10_relu_l2_1  0.309417       0.298954       0.221226   \n",
       "12         model_100_100_10_relu  0.158956       0.179260       0.506309   \n",
       "13    model_100_100_10_relu_l2_3  0.159751       0.177386       0.494665   \n",
       "14    model_100_100_10_relu_l2_2  0.031470       0.034046       0.163400   \n",
       "15    model_100_100_10_relu_l2_1  0.398609       0.381228       0.314021   \n",
       "\n",
       "    model_10_l2_1  model_1200_1200_10_relu  model_1200_1200_10_relu_l2_3  \\\n",
       "0        0.802539                 0.456832                      0.477428   \n",
       "1        0.787808                 0.419066                      0.431128   \n",
       "2        0.146373                 0.797927                      0.794041   \n",
       "3        0.000000                 0.865712                      0.863026   \n",
       "4        0.688288                 0.000000                      0.014549   \n",
       "5        0.684530                 0.010184                      0.000000   \n",
       "6        0.592348                 0.005339                      0.004576   \n",
       "7        0.091445                 0.539823                      0.548673   \n",
       "8        0.746138                 0.127683                      0.139850   \n",
       "9        0.765426                 0.123536                      0.153006   \n",
       "10       0.686045                 0.014907                      0.016627   \n",
       "11       0.118087                 0.772795                      0.774290   \n",
       "12       0.762582                 0.249021                      0.284989   \n",
       "13       0.760818                 0.269858                      0.303053   \n",
       "14       0.708366                 0.031918                      0.038078   \n",
       "15       0.144844                 0.830823                      0.833140   \n",
       "\n",
       "    model_1200_1200_10_relu_l2_2  model_1200_1200_10_relu_l2_1  \\\n",
       "0                       0.485810                      0.700036   \n",
       "1                       0.436706                      0.635798   \n",
       "2                       0.803109                      0.589378   \n",
       "3                       0.868397                      0.727842   \n",
       "4                       0.016368                      0.327837   \n",
       "5                       0.011518                      0.308196   \n",
       "6                       0.000000                      0.080336   \n",
       "7                       0.563422                      0.000000   \n",
       "8                       0.142857                      0.646070   \n",
       "9                       0.155111                      0.676227   \n",
       "10                      0.017659                      0.302030   \n",
       "11                      0.780269                      0.533632   \n",
       "12                      0.273387                      0.737201   \n",
       "13                      0.295643                      0.745110   \n",
       "14                      0.032926                      0.336208   \n",
       "15                      0.837775                      0.647740   \n",
       "\n",
       "    model_200_200_10_relu  model_200_200_10_relu_l2_3  \\\n",
       "0                0.489522                    0.448689   \n",
       "1                0.431388                    0.404799   \n",
       "2                0.795337                    0.786269   \n",
       "3                0.855864                    0.853178   \n",
       "4                0.019520                    0.022551   \n",
       "5                0.017095                    0.017944   \n",
       "6                0.008008                    0.007500   \n",
       "7                0.533923                    0.542773   \n",
       "8                0.000000                    0.143541   \n",
       "9                0.143139                    0.000000   \n",
       "10               0.018003                    0.017659   \n",
       "11               0.775785                    0.768311   \n",
       "12               0.213198                    0.237128   \n",
       "13               0.250148                    0.241553   \n",
       "14               0.029903                    0.040542   \n",
       "15               0.818076                    0.820394   \n",
       "\n",
       "    model_200_200_10_relu_l2_2  model_200_200_10_relu_l2_1  \\\n",
       "0                     0.507245                    0.786852   \n",
       "1                     0.468093                    0.748249   \n",
       "2                     0.800518                    0.306995   \n",
       "3                     0.861235                    0.472695   \n",
       "4                     0.024127                    0.600024   \n",
       "5                     0.022793                    0.581959   \n",
       "6                     0.008262                    0.370662   \n",
       "7                     0.542773                    0.079646   \n",
       "8                     0.144361                    0.734792   \n",
       "9                     0.144981                    0.760426   \n",
       "10                    0.000000                    0.564385   \n",
       "11                    0.778774                    0.000000   \n",
       "12                    0.253082                    0.776070   \n",
       "13                    0.292679                    0.779194   \n",
       "14                    0.037182                    0.609251   \n",
       "15                    0.831981                    0.278100   \n",
       "\n",
       "    model_100_100_10_relu  model_100_100_10_relu_l2_3  \\\n",
       "0                0.467728                    0.374805   \n",
       "1                0.430610                    0.337484   \n",
       "2                0.773316                    0.766839   \n",
       "3                0.845121                    0.845121   \n",
       "4                0.024612                    0.022672   \n",
       "5                0.020369                    0.019762   \n",
       "6                0.008644                    0.007754   \n",
       "7                0.519174                    0.507375   \n",
       "8                0.135065                    0.123308   \n",
       "9                0.147744                    0.112222   \n",
       "10               0.016856                    0.020640   \n",
       "11               0.745889                    0.744395   \n",
       "12               0.000000                    0.199420   \n",
       "13               0.258002                    0.000000   \n",
       "14               0.036734                    0.039646   \n",
       "15               0.799537                    0.801854   \n",
       "\n",
       "    model_100_100_10_relu_l2_2  model_100_100_10_relu_l2_1  \n",
       "0                     0.418273                    0.768171  \n",
       "1                     0.375357                    0.727367  \n",
       "2                     0.778497                    0.213731  \n",
       "3                     0.849597                    0.338406  \n",
       "4                     0.024733                    0.621605  \n",
       "5                     0.022551                    0.612997  \n",
       "6                     0.008644                    0.428626  \n",
       "7                     0.536873                    0.094395  \n",
       "8                     0.121668                    0.724402  \n",
       "9                     0.143271                    0.743060  \n",
       "10                    0.017544                    0.600275  \n",
       "11                    0.754858                    0.074738  \n",
       "12                    0.212618                    0.753009  \n",
       "13                    0.252223                    0.755780  \n",
       "14                    0.000000                    0.618210  \n",
       "15                    0.812283                    0.000000  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# df.to_csv('models_r_3_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmRbdyiyTT7J"
   },
   "source": [
    "Run Bayesian NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dllHvJyhhNPL",
    "outputId": "e783bd67-a76f-4da1-abf8-78078857aa4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8438871340453624\n"
     ]
    }
   ],
   "source": [
    "MODEL_BAYESIAN = bayes_models[0]\n",
    "\n",
    "eval_samples_list = [1]\n",
    "\n",
    "df_bayes = pd.DataFrame()\n",
    "df_bayes['names'] = model_names\n",
    "\n",
    "for j in range(len(eval_samples_list)):\n",
    "    eval_samples = eval_samples_list[j]\n",
    "    df_bayes['accuracy with '+str(eval_samples)] = [0. for i in range(16)]\n",
    "    \n",
    "    for i in range(16):\n",
    "        x_perturbed, y_perturbed, distortion = get_perturbations(i, 1.5)\n",
    "\n",
    "        acc = evaluate_bayesian(x_perturbed, y_perturbed, eval_samples)\n",
    "\n",
    "        df_bayes.iloc[i,j+1] = float(acc)\n",
    "    print(np.mean(df_bayes.iloc[:,j+1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fq-4-MDlhNUZ",
    "outputId": "46596f0f-fc6e-4be4-c73d-596c6b88ee4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>accuracy with 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_10</td>\n",
       "      <td>0.951397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>model_10_l2_3</td>\n",
       "      <td>0.946811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>model_10_l2_2</td>\n",
       "      <td>0.774391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>model_10_l2_1</td>\n",
       "      <td>0.834843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>model_100_100_10_relu</td>\n",
       "      <td>0.921983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>model_100_100_10_relu_l2_3</td>\n",
       "      <td>0.925279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>model_100_100_10_relu_l2_2</td>\n",
       "      <td>0.888622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>model_100_100_10_relu_l2_1</td>\n",
       "      <td>0.801564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>model_200_200_10_relu</td>\n",
       "      <td>0.914085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>model_200_200_10_relu_l2_3</td>\n",
       "      <td>0.921538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>model_200_200_10_relu_l2_2</td>\n",
       "      <td>0.864306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>model_200_200_10_relu_l2_1</td>\n",
       "      <td>0.743901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>model_1200_1200_10_relu</td>\n",
       "      <td>0.865702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>model_1200_1200_10_relu_l2_3</td>\n",
       "      <td>0.858214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>model_1200_1200_10_relu_l2_2</td>\n",
       "      <td>0.751977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>model_1200_1200_10_relu_l2_1</td>\n",
       "      <td>0.537581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           names  accuracy with 1\n",
       "0                       model_10         0.951397\n",
       "1                  model_10_l2_3         0.946811\n",
       "2                  model_10_l2_2         0.774391\n",
       "3                  model_10_l2_1         0.834843\n",
       "4          model_100_100_10_relu         0.921983\n",
       "5     model_100_100_10_relu_l2_3         0.925279\n",
       "6     model_100_100_10_relu_l2_2         0.888622\n",
       "7     model_100_100_10_relu_l2_1         0.801564\n",
       "8          model_200_200_10_relu         0.914085\n",
       "9     model_200_200_10_relu_l2_3         0.921538\n",
       "10    model_200_200_10_relu_l2_2         0.864306\n",
       "11    model_200_200_10_relu_l2_1         0.743901\n",
       "12       model_1200_1200_10_relu         0.865702\n",
       "13  model_1200_1200_10_relu_l2_3         0.858214\n",
       "14  model_1200_1200_10_relu_l2_2         0.751977\n",
       "15  model_1200_1200_10_relu_l2_1         0.537581"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "VnrFZjJzfnTE"
   },
   "outputs": [],
   "source": [
    "df_bayes.to_csv('bayes_4_0_r_1_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQIk_xdyfnbd"
   },
   "source": [
    "## Accuracy under Perturbation and Model Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "1QwdOeyZfneZ"
   },
   "outputs": [],
   "source": [
    "def prune(w, remove_ratio):\n",
    "    '''\n",
    "    Weights pruning.\n",
    "    This function depends on the knowledge that, model weights follows this format:\n",
    "    for each layer:\n",
    "        weight_mu\n",
    "        bias_mu\n",
    "        weight_rho\n",
    "        bias_rho\n",
    "    '''\n",
    "\n",
    "    sn_ratio = []\n",
    "    for i in range(0, len(w), 4):\n",
    "        sn_ratio.append(w[i]/tf.math.softplus(w[i+2]))\n",
    "        sn_ratio.append(w[i+1]/tf.math.softplus(w[i+3]))\n",
    "\n",
    "    sorted_ratio = []\n",
    "    for i in range(len(sn_ratio)):\n",
    "        sorted_ratio.append(np.argsort(np.reshape(abs(sn_ratio[i]), (-1,))))\n",
    "\n",
    "    new_weights = deepcopy(w)\n",
    "    for i in range(0, len(sorted_ratio), 2):\n",
    "        remove_until_1 = min(int(len(sorted_ratio[i]) * remove_ratio), (len(sorted_ratio[i])-1))\n",
    "        remove_until_2 = min(int(len(sorted_ratio[i+1]) * remove_ratio), (len(sorted_ratio[i+1])-1))\n",
    "        for j in range(remove_until_1):\n",
    "            rmv_idx = sorted_ratio[i][j]\n",
    "            idx1 = int(rmv_idx / w[i*2].shape[1])\n",
    "            idx2 = rmv_idx - idx1 * w[i*2].shape[1]\n",
    "            new_weights[i*2][idx1, idx2] = 0.0\n",
    "            new_weights[i*2+2][idx1, idx2] = -100.0\n",
    "        for j in range(remove_until_2):\n",
    "            idx = sorted_ratio[i+1][j]\n",
    "            new_weights[i*2+1][idx] = 0.0\n",
    "            new_weights[i*2+3][idx] = -100.0\n",
    "            \n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayes_2_0\n",
      "0.48967552185058594\n",
      "0.48672565817832947\n",
      "0.4601770043373108\n",
      "0.4336283206939697\n",
      "0.3687315583229065\n",
      "0.2507374584674835\n"
     ]
    }
   ],
   "source": [
    "print(bayes_names[5])\n",
    "MODEL_BAYESIAN = bayes_models[5] # rho initialized to -2\n",
    "eval_samples = 100\n",
    "\n",
    "w = MODEL_BAYESIAN.get_weights()\n",
    "w_archive = deepcopy(w)\n",
    "\n",
    "df_prune = pd.DataFrame()\n",
    "df_prune['names'] = model_names\n",
    "ratios = [0.25,0.5,0.75,0.9,0.95,0.98]\n",
    "\n",
    "for j in range(len(ratios)):\n",
    "\n",
    "    w = MODEL_BAYESIAN.get_weights()\n",
    "    ratio = ratios[j]\n",
    "    new_w = prune(w, ratio)\n",
    "    MODEL_BAYESIAN.set_weights(new_w)\n",
    "\n",
    "    df_prune[str(ratio)] = [0. for i in range(16)]\n",
    "\n",
    "    for i in range(16):\n",
    "        x_perturbed, y_perturbed, distortion = get_perturbations(i, 1.5)\n",
    "\n",
    "        acc = evaluate_bayesian(x_perturbed, y_perturbed, eval_samples)\n",
    "\n",
    "        df_prune.iloc[i,j+1] = float(acc)\n",
    "\n",
    "    # acc = evaluate_bayesian(x_test, y_test, eval_samples)\n",
    "\n",
    "    MODEL_BAYESIAN.set_weights(w_archive)\n",
    "    \n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_10</td>\n",
       "      <td>0.966351</td>\n",
       "      <td>0.963956</td>\n",
       "      <td>0.962040</td>\n",
       "      <td>0.941803</td>\n",
       "      <td>0.819064</td>\n",
       "      <td>0.538977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>model_10_l2_3</td>\n",
       "      <td>0.960700</td>\n",
       "      <td>0.961219</td>\n",
       "      <td>0.958236</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.810376</td>\n",
       "      <td>0.535019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>model_10_l2_2</td>\n",
       "      <td>0.759067</td>\n",
       "      <td>0.757772</td>\n",
       "      <td>0.753886</td>\n",
       "      <td>0.713731</td>\n",
       "      <td>0.568653</td>\n",
       "      <td>0.326425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>model_10_l2_1</td>\n",
       "      <td>0.829006</td>\n",
       "      <td>0.831692</td>\n",
       "      <td>0.824530</td>\n",
       "      <td>0.784244</td>\n",
       "      <td>0.638317</td>\n",
       "      <td>0.359893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>model_100_100_10_relu</td>\n",
       "      <td>0.946483</td>\n",
       "      <td>0.945468</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>0.908920</td>\n",
       "      <td>0.781871</td>\n",
       "      <td>0.517041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>model_100_100_10_relu_l2_3</td>\n",
       "      <td>0.949022</td>\n",
       "      <td>0.945762</td>\n",
       "      <td>0.943391</td>\n",
       "      <td>0.904861</td>\n",
       "      <td>0.787937</td>\n",
       "      <td>0.538826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>model_100_100_10_relu_l2_2</td>\n",
       "      <td>0.927315</td>\n",
       "      <td>0.924068</td>\n",
       "      <td>0.909620</td>\n",
       "      <td>0.851831</td>\n",
       "      <td>0.688655</td>\n",
       "      <td>0.428491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>model_100_100_10_relu_l2_1</td>\n",
       "      <td>0.789108</td>\n",
       "      <td>0.787949</td>\n",
       "      <td>0.779838</td>\n",
       "      <td>0.743917</td>\n",
       "      <td>0.600232</td>\n",
       "      <td>0.329085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>model_200_200_10_relu</td>\n",
       "      <td>0.948599</td>\n",
       "      <td>0.946685</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.896377</td>\n",
       "      <td>0.755161</td>\n",
       "      <td>0.495967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>model_200_200_10_relu_l2_3</td>\n",
       "      <td>0.949612</td>\n",
       "      <td>0.948428</td>\n",
       "      <td>0.938298</td>\n",
       "      <td>0.906065</td>\n",
       "      <td>0.764636</td>\n",
       "      <td>0.502829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>model_200_200_10_relu_l2_2</td>\n",
       "      <td>0.904598</td>\n",
       "      <td>0.907121</td>\n",
       "      <td>0.879486</td>\n",
       "      <td>0.815618</td>\n",
       "      <td>0.655888</td>\n",
       "      <td>0.419677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>model_200_200_10_relu_l2_1</td>\n",
       "      <td>0.730942</td>\n",
       "      <td>0.736921</td>\n",
       "      <td>0.723468</td>\n",
       "      <td>0.681614</td>\n",
       "      <td>0.547085</td>\n",
       "      <td>0.315396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>model_1200_1200_10_relu</td>\n",
       "      <td>0.917192</td>\n",
       "      <td>0.916707</td>\n",
       "      <td>0.898157</td>\n",
       "      <td>0.843477</td>\n",
       "      <td>0.692774</td>\n",
       "      <td>0.445805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>model_1200_1200_10_relu_l2_3</td>\n",
       "      <td>0.916950</td>\n",
       "      <td>0.912342</td>\n",
       "      <td>0.894399</td>\n",
       "      <td>0.836324</td>\n",
       "      <td>0.683196</td>\n",
       "      <td>0.437197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>model_1200_1200_10_relu_l2_2</td>\n",
       "      <td>0.820389</td>\n",
       "      <td>0.819880</td>\n",
       "      <td>0.790136</td>\n",
       "      <td>0.724037</td>\n",
       "      <td>0.591331</td>\n",
       "      <td>0.387695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>model_1200_1200_10_relu_l2_1</td>\n",
       "      <td>0.489676</td>\n",
       "      <td>0.486726</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.433628</td>\n",
       "      <td>0.368732</td>\n",
       "      <td>0.250737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           names      0.25       0.5      0.75       0.9  \\\n",
       "0                       model_10  0.966351  0.963956  0.962040  0.941803   \n",
       "1                  model_10_l2_3  0.960700  0.961219  0.958236  0.938392   \n",
       "2                  model_10_l2_2  0.759067  0.757772  0.753886  0.713731   \n",
       "3                  model_10_l2_1  0.829006  0.831692  0.824530  0.784244   \n",
       "4          model_100_100_10_relu  0.946483  0.945468  0.939376  0.908920   \n",
       "5     model_100_100_10_relu_l2_3  0.949022  0.945762  0.943391  0.904861   \n",
       "6     model_100_100_10_relu_l2_2  0.927315  0.924068  0.909620  0.851831   \n",
       "7     model_100_100_10_relu_l2_1  0.789108  0.787949  0.779838  0.743917   \n",
       "8          model_200_200_10_relu  0.948599  0.946685  0.938893  0.896377   \n",
       "9     model_200_200_10_relu_l2_3  0.949612  0.948428  0.938298  0.906065   \n",
       "10    model_200_200_10_relu_l2_2  0.904598  0.907121  0.879486  0.815618   \n",
       "11    model_200_200_10_relu_l2_1  0.730942  0.736921  0.723468  0.681614   \n",
       "12       model_1200_1200_10_relu  0.917192  0.916707  0.898157  0.843477   \n",
       "13  model_1200_1200_10_relu_l2_3  0.916950  0.912342  0.894399  0.836324   \n",
       "14  model_1200_1200_10_relu_l2_2  0.820389  0.819880  0.790136  0.724037   \n",
       "15  model_1200_1200_10_relu_l2_1  0.489676  0.486726  0.460177  0.433628   \n",
       "\n",
       "        0.95      0.98  \n",
       "0   0.819064  0.538977  \n",
       "1   0.810376  0.535019  \n",
       "2   0.568653  0.326425  \n",
       "3   0.638317  0.359893  \n",
       "4   0.781871  0.517041  \n",
       "5   0.787937  0.538826  \n",
       "6   0.688655  0.428491  \n",
       "7   0.600232  0.329085  \n",
       "8   0.755161  0.495967  \n",
       "9   0.764636  0.502829  \n",
       "10  0.655888  0.419677  \n",
       "11  0.547085  0.315396  \n",
       "12  0.692774  0.445805  \n",
       "13  0.683196  0.437197  \n",
       "14  0.591331  0.387695  \n",
       "15  0.368732  0.250737  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prune.to_csv('prune_2_0_r_1_5_s_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEuCp1JvfnkS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oz8Ab9uRXk95"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrjFYjGbXlBe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0KIGbF0XlFj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "perturbation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
